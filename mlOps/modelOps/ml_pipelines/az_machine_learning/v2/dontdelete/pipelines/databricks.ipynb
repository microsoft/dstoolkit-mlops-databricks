{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b91572a-3df1-48ec-b8c4-a25664a31f64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "ml_client = MLClient(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    subscription_id=\"\",\n",
    "    resource_group_name=\"databricks-sandbox-rg\",\n",
    "    workspace_name=\"amlsandbox-eco3\",\n",
    "    )\n",
    "\n",
    "print(ml_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6a64f00-a05e-4676-9949-9457ec973ecb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "cpu_compute_target = \"ciaranh1\"\n",
    "\n",
    "try:\n",
    "    # let's see if the compute target already exists\n",
    "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
    "    print(\n",
    "        f\"You already have a cluster named {cpu_compute_target}, we'll reuse it as is.\"\n",
    "    )\n",
    "\n",
    "except Exception:\n",
    "    print(\"Creating a new cpu compute target...\")\n",
    "\n",
    "    # Let's create the Azure ML compute object with the intended parameters\n",
    "    cpu_cluster = AmlCompute(\n",
    "        # Name assigned to the compute cluster\n",
    "        name=\"cpu-cluster\",\n",
    "        # Azure ML Compute is the on-demand VM service\n",
    "        type=\"amlcompute\",\n",
    "        # VM Family\n",
    "        size=\"STANDARD_DS3_V2\",\n",
    "        # Minimum running nodes when there is no job running\n",
    "        min_instances=0,\n",
    "        # Nodes in cluster\n",
    "        max_instances=4,\n",
    "        # How many seconds will the node running after the job termination\n",
    "        idle_time_before_scale_down=180,\n",
    "        # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
    "        tier=\"Dedicated\",\n",
    "    )\n",
    "\n",
    "    # Now, we pass the object to MLClient's create_or_update method\n",
    "    cpu_cluster = ml_client.begin_create_or_update(cpu_cluster)\n",
    "\n",
    "print(\n",
    "    f\"AMLCompute with name {cpu_cluster.name} is created, the compute size is {cpu_cluster.size}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b28d4b97-3430-4efd-ad82-fb4afd92da53",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "custom_env_name = \"aml-scikit-learn\"\n",
    "\n",
    "pipeline_job_env = Environment(\n",
    "    name=custom_env_name,\n",
    "    description=\"Custom environment for Credit Card Defaults pipeline\",\n",
    "    tags={\"scikit-learn\": \"0.24.2\"},\n",
    "    conda_file=os.path.join(\"../dependencies/\", \"conda.yaml\"),\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
    "    version=\"0.2.0\",\n",
    "\n",
    ")\n",
    "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
    "\n",
    "print(\n",
    "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76a0888b-3d2a-435d-8f58-297de89d045c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_prep_src_dir = \"../components/databricks\"\n",
    "print(data_prep_src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c5baa7c-bdc6-43e0-bc50-7d860561d0d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input, Output\n",
    "\n",
    "list_dbx_clusters = command(\n",
    "    name=\"Databricks E2E ML Workflow\",\n",
    "    display_name=\"Databricks E2E ML Workflow\",\n",
    "    description=\"Invoke a Databricks Pipeline\",\n",
    "    inputs={\n",
    "        \"test_train_ratio\": Input(type=\"number\")\n",
    "    },\n",
    "    outputs=dict(\n",
    "        train_data=Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "        test_data=Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "    ),\n",
    "    # The source folder of the component\n",
    "    code=data_prep_src_dir,\n",
    "    command=\"\"\"python listclusters.py --test_train_ratio ${{inputs.test_train_ratio}} \\\n",
    "            --train_data ${{outputs.train_data}} --test_data ${{outputs.test_data}} \\\n",
    "            \"\"\",\n",
    "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d7c79f9-7aa2-4bc0-9541-a92a8e81d8db",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(list_dbx_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfdbf00f-2c0d-4fb2-b35c-ea73fb7bde2c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# the dsl decorator tells the sdk that we are defining an Azure ML pipeline\n",
    "from azure.ai.ml import dsl, Input, Output\n",
    "\n",
    "pipeline_job_test_train_ratio = 0.2\n",
    "@dsl.pipeline(\n",
    "    compute=cpu_compute_target,\n",
    "    description=\"E2E data_perp-train pipeline\",\n",
    ")\n",
    "def dbx_pipeline(\n",
    "    pipeline_job_test_train_ratio,\n",
    "):\n",
    "    # using data_prep_function like a python call with its own inputs\n",
    "    data_prep_job = list_dbx_clusters(\n",
    "        test_train_ratio=pipeline_job_test_train_ratio,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f65cfb4-c925-4f5c-a3c8-016676057906",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pipeline = dbx_pipeline(\n",
    "    pipeline_job_test_train_ratio=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "378b0352-a52d-4c14-84e6-bc149e240710",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# submit the pipeline job\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline,\n",
    "    # Project's name\n",
    "    experiment_name=\"dbx_list_clusters\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b562667-07dc-496f-a768-7436130662c7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(pipeline_job)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "databricks",
   "notebookOrigID": 535341568642118,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
