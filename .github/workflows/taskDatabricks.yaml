name:                         Tasks Databricks
on:
  workflow_call:
    inputs:
      ENVIRONMENT:
        required: true
        type: string
      DBX_REPO_BRANCH:
        required: false
        type: string
      SCRIPT_LANGUAGE:
        required: false
        type: string
      DevOps_Agent:
        required: true
        type: string 
        default: GitHub
    secrets:
      ARM_TENANT_ID:
        required: true
      ARM_CLIENT_ID:
        required: true
      ARM_CLIENT_SECRET:
        required: true
      PAT_GITHUB:
        required: true


jobs:
  build:
    name:                         ${{ inputs.ENVIRONMENT }} Environment Deployment
    runs-on:                      ubuntu-latest
    #runs-on: self-hosted
    environment:                  ${{ inputs.ENVIRONMENT }}
    steps:      
      - name:                     Checkout
        uses:                     actions/checkout@v2



#################################/
##  Set Python.                                      
#################################/
      - name:                     Setup Python
        uses:                     actions/setup-python@v4
        with:
          python-version:         "3.8"
    
#################################/
##  Dependencies/ Install                                              
#################################/
      - shell: bash
        name:  Tests and Dependency Install
        run: |

          pip3 install --upgrade pip

          #sudo apt update && sudo apt upgrade && sudo apt install jq -y
          

          az extension add -n azure-cli-ml

          # Do a python pip install so that modules can be found from python tasks
          python -m pip install requests
          python -m pip install python-dotenv



          pip3 install --upgrade azure-cli
          pip3 install azure-mgmt-storage==21.0.0
          #pip3 install  azure-databricks-sdk-python
          az config set extension.use_dynamic_install=yes_without_prompt
          
          pip3 install azureml
          pip3 install azureml-core
          pip3 install azureml.pipeline
          

#################################/
##  Authenticate/Login To Azure                                               
#################################/
      - name:                     Service Principal Login
        run:                      ${{ inputs.SCRIPT_LANGUAGE }} infrastructure/databricks/databricks_utils/${{ inputs.SCRIPT_LANGUAGE }}/utils_azure_login.py
        env:
          ARM_CLIENT_ID:          ${{ secrets.ARM_CLIENT_ID }}    
          ARM_CLIENT_SECRET:      ${{ secrets.ARM_CLIENT_SECRET }}
          ARM_TENANT_ID:          ${{ secrets.ARM_TENANT_ID }}

#################################/
## Deploy Azure Infrastructure.                                               
#################################/
      - name:                     Deploy Azure Resources
        run:                      ${{ inputs.SCRIPT_LANGUAGE }} infrastructure/databricks/databricks_utils/${{ inputs.SCRIPT_LANGUAGE }}/utils_create_azure_resources.py
        env:
          ENVIRONMENT:            ${{ inputs.ENVIRONMENT }}



#################################/
##  Save Dynamically Generated Env Variable                                               
#################################/
      - name:                     Set Env Variables 
        run:                      bash infrastructure/databricks/databricks_utils/bash/utilsSetEnvVariables.sh
        env:
          ENVIRONMENT:            ${{ inputs.ENVIRONMENT }}
          DevOps_Agent:           ${{ inputs.DevOps_Agent }} 


#################################/
##  Generate AAD Tokens                                              
#################################/
      - name:                     Generate AAD Tokens
        run:                      ${{ inputs.SCRIPT_LANGUAGE }} infrastructure/databricks/databricks_utils/${{ inputs.SCRIPT_LANGUAGE }}/utils_create_authentication_tokens.py
        env:
          ENVIRONMENT:            ${{ inputs.ENVIRONMENT }}
          ARM_CLIENT_ID:          ${{ secrets.ARM_CLIENT_ID }}    
          ARM_CLIENT_SECRET:      ${{ secrets.ARM_CLIENT_SECRET }}
          ARM_TENANT_ID:          ${{ secrets.ARM_TENANT_ID }}

#################################/
##  RBAC Assignments                                           
#################################/
      - name:                     Assign RBAC Permissions 
        run:                      bash infrastructure/databricks/databricks_utils/bash/utilsCreateRoleBasedAccess.sh
        env:
          ENVIRONMENT:            ${{ inputs.ENVIRONMENT }}

#################################/
##  Generate Python Wheel Files                                            
#################################/
      - name:                     'Create NYC Taxi Package Wheel File'
        run: |
          pip3 install wheel
          ls
          cd data_science/src_nyc_taxi
          ls
          python setup.py sdist bdist_wheel


#################################/
##  PAT Token                                           
#################################/
      - name:                     Create And Store PAT Token In Key Vault
        run:                      bash infrastructure/databricks/databricks_utils/bash/utilsCreateDatabricksToken.sh
        env:
          DevOps_Agent:           ${{ inputs.DevOps_Agent }} 

          
#################################/
##  Git Config                                           
#################################/
  
      - name:                     Git Config
        run:                      ${{ inputs.SCRIPT_LANGUAGE }} infrastructure/databricks/databricks_utils/${{ inputs.SCRIPT_LANGUAGE }}/utils_git_configuration.py
        env:
          PAT_GITHUB:             ${{ secrets.PAT_GITHUB }}

#################################/
##  Create Repos                                           
#################################/
      - name:                     Create Databricks Repos
        run:                      ${{ inputs.SCRIPT_LANGUAGE }} infrastructure/databricks/databricks_utils/${{ inputs.SCRIPT_LANGUAGE }}/utils_create_repo_folder.py
        env:
          ARM_CLIENT_ID:          ${{ secrets.ARM_CLIENT_ID }} 

#################################/
##  Secret Scopes                                           
#################################/
      - name:                     Save Databricks SP Credentials Within Secret Scopes
        run:                      ${{ inputs.SCRIPT_LANGUAGE }} infrastructure/databricks/databricks_utils/${{ inputs.SCRIPT_LANGUAGE }}/utils_create_secret_scopes.py
        env:
          ARM_CLIENT_ID:          ${{ secrets.ARM_CLIENT_ID }}
          ARM_CLIENT_SECRET:      ${{ secrets.ARM_CLIENT_SECRET }}
          ARM_TENANT_ID:          ${{ secrets.ARM_TENANT_ID }}
          
#################################/
##  Configure CLI                                           
#################################/
      #- name:                     Install + Configure Databricks CLI
      #  run:                      bash MLOps/DevOps/Utilities/bash/utilsDatabricksCLIConfig.sh
      #  env:
      #    DevOps_Agent:           ${{ inputs.DevOps_Agent }} 

#################################/
##  Repo Pull                                           
#################################/
# 15. Databricks Repo Pull
      - name:                     Repo Pull
        run:                      bash infrastructure/databricks/databricks_utils/bash/utilsRepoPull.sh
        env:
          PULL_BRANCH:            ${{ github.ref_name }}
          DBX_REPO_BRANCH:        ${{ inputs.DBX_REPO_BRANCH}} 


#################################/
##  Create Cluster                                           
#################################/
      - name:                     Create Databricks Clusters
        run:                      ${{ inputs.SCRIPT_LANGUAGE }} infrastructure/databricks/databricks_utils/${{ inputs.SCRIPT_LANGUAGE }}/utils_create_cluster.py


        
#################################/
##  Build AML Pipelines (Running Databricks Notebooks From AML Pipeline)  
## Functionality Under Development (Not yet parameterized to work on general deployments)                                        
#################################/
# 15. AML Pipeline
      - name:                       Azure Machine Learning Pipeline For DBX Notebooks
        run:                        ${{ inputs.SCRIPT_LANGUAGE }} mlOps/nyc_taxi/aml_pipelines/v1/nyc_pipeline.py
        env:
          DATABRICKS_COMPUTE_NAME:  'mlclusterlink'
          DATABRICKS_CLUSTER_NAME:  'Unity_Cluster_13_ML'
          ARM_CLIENT_ID:            ${{ secrets.ARM_CLIENT_ID }}
          ARM_CLIENT_SECRET:        ${{ secrets.ARM_CLIENT_SECRET }}
          ARM_TENANT_ID:            ${{ secrets.ARM_TENANT_ID }}


      - shell:                    bash
        name:                     Set Up DBX Environment Variables
        run: |
          DATABRICKS_TOKEN=$(az keyvault secret show --name "dbkstoken" --vault-name $AZ_KEYVAULT_NAME --query "value" -o tsv)
          #echo $DATABRICKS_TOKEN
          echo "DATABRICKS_TOKEN=$DATABRICKS_TOKEN" >> $GITHUB_ENV


#################################/
##  DBX Deploy Jobs / Workflows                                            
#################################/
      - shell:                    bash
        name:                     DBX Deploy - Workflow Artifacts (CD) 
        run: |

          pip3 install dbx

          databricks -h 
          databricks fs ls

          dbx configure \
          --enable-inplace-jinja-support \
          --profile $ENVIRONMENT
        
          dbx deploy \
          --workflows NYC_TAXI_PIPELINE \
          --no-package \
          --deployment-file mlOps/nyc_taxi/databricks_pipelines/workflow.yaml \
          -e $ENVIRONMENT \
          --jinja-variables-file=mlOps/nyc_taxi/databricks_pipelines/workflow_params.yaml

        env:
          ENVIRONMENT:            ${{ inputs.ENVIRONMENT }} 

#################################/
##  Install Wheel On Interactive Cluster                                            
#################################/
      #- name:                     'Install NYC Taxi Package Wheel File On Interactive Cluster'
      #  run: |

          #python setup.py sdist bdist_wheel

      #    cd data_science/src_nyc_taxi/dist
      #    ls # List the contents of the directory - Wheel File Should Exist Here

      #    wheel_file_name=$( ls -d -- *.whl )
      #    echo "Wheel File Name: $wheel_file_name"

      #    databricks fs rm dbfs:/FileStore/wheel_files/$wheel_file_name
      #    databricks fs cp $wheel_file_name dbfs:/FileStore/wheel_files/$wheel_file_name --overwrite


      #    databricks clusters list --output JSON
      #    CLUSTER_ID=$(databricks clusters list --output JSON | jq -r '.clusters[] | select(.cluster_name == "ml_cluster") | .cluster_id')

          # TO DO CHECK IF CLUSTER IS ON, AND IF NOT, TURN IT ON

      #    databricks libraries uninstall --cluster-id "$CLUSTER_ID" --whl dbfs:/FileStore/wheel_files/$wheel_file_name
      #    databricks libraries install --cluster-id $CLUSTER_ID --whl dbfs:/FileStore/wheel_files/$wheel_file_name
          
      #    databricks clusters restart --cluster-id $CLUSTER_ID

















                                                      # DEPRECATED

###################################################################################################################################################################//
##                                                                      Create Jobs  
## Deprecated: Use for reference purposes only                                          
###################################################################################################################################################################//
# 13.   Create Databricks Jobs (Linked To Git Repo)
#      - name:                 Create Databricks Jobs
#        run:                  python .github/MLOps_Engineer/Utilities/Python/utilsCreateJob.py

###################################################################################################################################################################//
##                                                                      Create Wheel Files & Upload
## Deprecated: Use for reference purposes only                                          
###################################################################################################################################################################//
# 16. Databricks Wheel File Creation + DBFS/Cluster Upload
      #- name:                   Create Wheel Files & Upload To DBFS
      #  run:                    bash .github/MLOps_Engineer/Utilities/Bash/utilsWheelUpload.sh